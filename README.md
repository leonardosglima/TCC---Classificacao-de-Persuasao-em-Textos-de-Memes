# Classifica√ß√£o de Persuas√£o em Textos de Memes: Uma Abordagem Baseada em Engenharia de Caracter√≠sticas

## Monografia apresentada √† Escola Nacional de Ci√™ncias Estat√≠sticas do Instituto Brasileiro de Geografia e Estat√≠stica, como requisito parcial √† obten√ß√£o do t√≠tulo de Bacharel em Estat√≠stica, sob orienta√ß√£o do Prof. Eduardo Corr√™a Gon√ßalves.

O conte√∫do apresentado neste `README.md` trata-se de um resumo do trabalho. O trabalho completo pode ser acessado neste mesmo reposit√≥rio.

### Resumo

A propaganda visa influenciar a opini√£o p√∫blica para promover uma agenda espec√≠fica,
incentivando opini√µes contr√°rias ou a favor. Para isso, emprega t√©cnicas de persuas√£o,
utilizando uma comunica√ß√£o direcionada a moldar a opini√£o de quem recebe a informa√ß√£o,
podendo ser disseminada por diversos meios. Paralelamente, nas redes sociais, os
memes se mostram como uma poderosa ferramenta comunicativa, capazes de se espalhar
rapidamente e atingir um grande n√∫mero de pessoas. Assim, os memes podem ser um
ve√≠culo eficaz para a dissemina√ß√£o de propaganda. Na literatura, j√° existem estudos sobre
a detec√ß√£o computacional de propaganda em textos de artigos. No entanto, apenas recentemente
os pesquisadores come√ßaram a investigar a classifica√ß√£o de persuas√£o em memes,
que representa ambiente mais desafiador. Este trabalho aborda a classifica√ß√£o de persuas√£o
em textos de memes, utilizando algoritmos de aprendizado de m√°quina. A abordagem
√© baseada na engenharia de caracter√≠sticas, uma estrat√©gia usada para transformar texto
(dado n√£o estruturado) em um formato adequado para os algoritmos de classifica√ß√£o.
Ser√£o utilizados modelos de √°rvore de decis√£o, floresta aleat√≥ria e regress√£o log√≠stica.

Palavras-chaves: `Persuas√£o.` `Propaganda.` `Meme.` `Classifica√ß√£o.` `Engenharia de Caracter√≠sticas.`
`Processamento de Linguagem Natural.` `Aprendizado de M√°quina.`

### Introdu√ß√£o

Nos √∫ltimos anos, os memes emergiram como uma forma peculiar e poderosa de
comunica√ß√£o na era digital. Embora popularizados no ambiente online, √© dif√≠cil precisar
com rigor o momento em que conte√∫dos que circulam na internet passaram a ser reconhecidos
como memes (CHAGAS, 2021). Sabe-se que nos anos 90, tornou-se corriqueiro
traduzir memes como piadas e outras formas virais que ganhavam r√°pido alcance em
f√≥runs de discuss√£o online e newgroups. Na era da internet, esses elementos de m√≠dia compartilh√°vel
t√™m a habilidade de se espalhar rapidamente pelo mundo atrav√©s da intera√ß√£o
social (WANG; WOOD, 2011) e, hoje, se encontram quase que onipresentes nas redes
sociais. Desde um ambiente de humor at√© a manifesta√ß√£o pol√≠tica, sua natureza altamente
compartilh√°vel e adapt√°vel os torna ideais para o ambiente din√¢mico das redes sociais, se
destacando pela sua capacidade de atrair e envolver as pessoas (CHAGAS, 2021).

De acordo com Merriam-Webster (2023), o fen√¥meno tem origem ainda na d√©cada
de 70. A palavra "meme"foi cunhada em 1976 pelo renomado bi√≥logo brit√¢nico Richard
Dawkins em seu livro "The Selfish Gene". Dawkins introduziu o termo como uma unidade
cultural que se replica e se transmite de pessoa para pessoa por meio da imita√ß√£o, semelhante
ao conceito de gene na biologia. Ele derivou a palavra "meme"do grego "mimema",
que significa "algo imitado". Dawkins usou os memes como uma forma de explicar como
ideias, comportamentos, rituais e outras formas de cultura s√£o transmitidas e evoluem ao
longo do tempo (DAWKINS, 1976). Segundo Dawkins, exemplos de memes s√£o melodias,
ideias, frases de efeito e at√© mesmo moda, argumentando que, assim como genes, os memes
competem entre si pela aten√ß√£o e reprodu√ß√£o, e aqueles que s√£o mais adapt√°veis e
atraentes t√™m mais chances de se espalhar e sobreviver.

Desde ent√£o, o conceito de meme expandiu-se para al√©m do dom√≠nio da biologia,
tornando-se uma parte fundamental da cultura digital contempor√¢nea, onde memes s√£o
compartilhados e adaptados em uma escala global. Em uma analogia com a biologia,
memes podem ser unidades culturais que se propagam e se adaptam por meio do compartilhamento
online. Plataformas como Instagram, Facebook, TikTok, Reddit e X (antigo
Twitter) servem como espa√ßos de cria√ß√£o, compartilhamento e discuss√£o de memes.

No entanto, por tr√°s de sua aparente trivialidade, os memes n√£o apenas podem
refletir os interesses e preocupa√ß√µes de uma gera√ß√£o conectada, mas tamb√©m podem ser
utilizados como campanhas de influ√™ncia por parte de governos (ZAKEM; MCBRIDE;
HAMMERBERG, 2021), o que pode impactar ativamente a maneira como percebemos e
interpretamos o mundo ao nosso redor. Desde coment√°rios sociais at√© cr√≠ticas pol√≠ticas, os
memes se tornaram uma importante ferramenta para a express√£o (MIHAILIDIS, 2020), podendo assumir a capacidade de moldar opini√µes.

Essa mesma capacidade dos memes de influenciar as percep√ß√µes e opini√µes pode ser
manipulada para espalhar desinforma√ß√£o e propaganda, atrav√©s de t√©cnicas de persuas√£o.
Propagandas possuem o objetivo de influenciar a opini√£o das pessoas com o prop√≥sito de
expandir uma agenda espec√≠fica (MARTINO et al., 2020). Com o r√°pido compartilhamento
e dissemina√ß√£o dos memes nas redes sociais, tornou-se cada vez mais f√°cil para indiv√≠duos
e grupos com interesses espec√≠ficos explorarem essa forma de comunica√ß√£o para promover
agendas pol√≠ticas, disseminar teorias da conspira√ß√£o e distorcer fatos. A natureza r√°pida
e concisa dos memes pode simplificar quest√µes complexas e levar a uma compreens√£o
superficial ou distorcida de eventos e quest√µes importantes. Al√©m disso, a viralidade dos
memes pode amplificar mensagens enganosas ou prejudiciais, aumentando sua influ√™ncia
e impacto.

Diferentes t√©cnicas de persuas√£o podem ser aplicadas em memes, aproveitando sua
capacidade de transmitir mensagens de forma r√°pida e eficaz. O uso de fal√°cias l√≥gicas,
com o uso de humor e ironia, pode tornar uma mensagem mais cativante e persuasiva, ao
mesmo tempo em que tenta suavizar poss√≠veis resist√™ncias do p√∫blico-alvo. Por exemplo,
a Figura 1 ilustra um meme, em ingl√™s, que retrata a congressista americana Ilhan Omar
junto ao ex-presidente dos Estados Unidos, Donald Trump. Neste meme, a associa√ß√£o √©
feita entre a express√£o de desgosto em rela√ß√£o ao ex-presidente e o terrorismo.

Este trabalho pretende utilizar t√©cnicas de Processamento de Linguagem Natural
(PLN) para criar um sistema capaz de classificar um meme como normal ou persuasivo
unicamente em fun√ß√£o de seu texto. O Processamento de Linguagem Natural √© um
campo de pesquisa que tem como objetivo investigar e propor m√©todos e sistemas de
processamento computacional da linguagem humana (CASELI; NUNES, 2024). Ele funciona
como como uma interse√ß√£o entre ci√™ncia da computa√ß√£o, intelig√™ncia artificial e
lingu√≠stica computacional, oferecendo as ferramentas necess√°rias para os computadores
entenderem a nossa linguagem (LOPEZ; KALITA, 2017). O trabalho empregar√° uma
abordagem baseada em engenharia de caracter√≠sticas (feature engineering), que consiste
na transforma√ß√£o dos textos dos memes (dados brutos) em vetores num√©ricos que s√£o
exigidos pelos algoritmos de classifica√ß√£o (NARGESIAN et al., 2017; ZHENG; CASARI,
2018).

<img src="https://github.com/user-attachments/assets/d14d8118-ddfb-4940-8835-e0bb83ec86f9" alt="Figura 1" width="400"/>

#### Justificativa

A utiliza√ß√£o de t√©cnicas de persuas√£o em memes √© um problema do mundo moderno,
visto que pode levar a propaga√ß√£o de desinforma√ß√£o e influenciar a percep√ß√£o do
p√∫blico sobre diversos assuntos atrav√©s de m√≠dias sociais na internet. Como este problema
√© relativamente novo, ainda h√° uma car√™ncia de estudos sobre o tema. Embora existam
pesquisas focadas na identifica√ß√£o de propaganda em textos de artigos (CRUZ; ROCHA;
CARDOSO, 2019; MARTINO; BARR√ìN-CEDE√ëO; NAKOV, 2019), apenas recentemente
os pesquisadores come√ßaram a investigar e estudar a classifica√ß√£o e detec√ß√£o de propaganda em textos de memes. Trata-se de um problema importante e relevante, dado
o vasto alcance e a r√°pida dissemina√ß√£o que os memes podem atingir.

#### Objetivos

O objetivo deste trabalho √© criar um sistema de classifica√ß√£o de textos curtos,
especificamente aplicado √† an√°lise de textos de memes, de forma a classificar se o conte√∫do
do texto √© persuasivo ou n√£o. Ao desenvolver um sistema capaz de identificar de forma
eficaz a presen√ßa de propaganda em memes, este trabalho poder√° fornecer um material
para pesquisas futuras sobre o tema. A classifica√ß√£o em textos de memes se encontra
em um contexto desafiador, visto que os textos tendem a ser muito curtos e informais,
podendo empregar linguagem coloquial e refer√™ncias culturais. Com o objetivo de tentar
a compreens√£o sobre o tema, este trabalho ter√° como foco o uso de t√©cnicas de engenharia
de caracter√≠sticas e de algoritmos capazes de gerar modelos interpret√°veis (FREITAS,
2014), isto √©, modelos que possuem a habilidade de ‚Äúexplicar‚Äù as suas classifica√ß√µes para
os usu√°rios. Mais especificamente, os algoritmos de classifica√ß√£o utilizados nesse trabalho
s√£o √Årvore de Decis√£o CART (BREIMAN et al., 1984), Regress√£o Log√≠stica (JURAFSKY;
MARTIN, 2024a) e Floresta Aleat√≥ria (Random Forest)1 (BREIMAN, 2001).

### Base de Dados

O trabalho utilizar√° a base de dados fornecida na competi√ß√£o SemEval 2024 (SemEval,
2024). Nesta competi√ß√£o, diversas equipes competem entre si com o objetivo de
construir modelos para identificar as diferentes t√©cnicas de persuas√£o que podem estar
sendo utilizadas ou n√£o nos textos dos memes. As equipes tiveram seus desempenhos
medidos atrav√©s de m√©tricas avaliativas, tais como o F1-Score (JURAFSKY; MARTIN,
2024c). A competi√ß√£o, iniciada nos √∫ltimos meses de 2023 e finalizada em 2024 foi organizada
por pesquisadores da It√°lia, Fran√ßa, Bulg√°ria, Emirados √Årabes Unidos e Catar. At√©
o momento do desenvolvimento deste trabalho, n√£o havia sido publicado nenhum artigo
elaborado por membros das equipes participantes da competi√ß√£o.

A base de dados fornecida pela organiza√ß√£o da competi√ß√£o foi dividida em tr√™s
conjuntos distintos: treino, valida√ß√£o e teste. Cada conjunto de dados possui as seguintes
vari√°veis: "id"(identificador √∫nico para cada observa√ß√£o), "text" (texto do meme), "labels"
(classifica√ß√µes relacionadas aos m√©todos de persuas√£o presentes no texto, ou indicando
a aus√™ncia deles) e "link" (link para abrir a imagem do meme). A coluna ‚Äúlabels‚Äù pode
estar rotulada com mais de uma classifica√ß√£o de persuas√£o diferente ao mesmo tempo.
Essa estrutura√ß√£o dos dados permite uma an√°lise detalhada e sistem√°tica dos textos,
auxiliando a constru√ß√£o e avalia√ß√£o de modelos de classifica√ß√£o.

A base de treino possui 7.000 observa√ß√µes e ser√° usada nesse trabalho para treinar
diferentes modelos de classifica√ß√£o. A base de valida√ß√£o possui 500 observa√ß√µes e foi utilizada
pelos competidores em um est√°gio preliminar da competi√ß√£o. Ela n√£o ser√° utilizada
no presente TCC. J√° a base de teste possui 1.000 observa√ß√µes e ser√° utilizada para estimar
o desempenho preditivo dos modelos, onde ser√£o verificadas as medidas de acur√°cia,
precis√£o, recall e F1-Score (JURAFSKY; MARTIN, 2024c).

### Classifica√ß√£o das T√©cnicas de Persuas√£o

De acordo com os organizadores da competi√ß√£o SemEval 2024, h√° 20 t√©cnicas de
persuas√£o distintas que podem ser aplicadas em textos. Essas t√©cnicas podem ser aplicadas
de forma isolada ou em conjunto com outras de forma simult√¢nea. As t√©cnicas podem ser encontradas [neste link](https://propaganda.math.unipd.it/semeval2024task4/definitions.html).

### An√°lise Explorat√≥ria

Cada observa√ß√£o de cada uma das tr√™s bases est√° rotulada com as t√©cnicas de
persuas√£o que est√£o sendo utilizadas no texto do meme, caso
o texto tenha conte√∫do persuasivo. A base de treino possui todas as 20 t√©cnicas em seus
textos. A Figura 2 exibe a frequ√™ncia de cada t√©cnica na base de treino. No total, as
t√©cnicas foram empregadas 11.290 vezes.

![Figura 2 v2](https://github.com/user-attachments/assets/f134b354-b916-43ab-bf97-2f9bad24db99)

A t√©cnica Smears destaca-se como a principal estrat√©gia de persuas√£o adotada
nos memes, respondendo por 17,63% de todas as t√©cnicas utilizadas. Em seguida, a t√©cnica
Loaded Language ocupa a posi√ß√£o de segunda mais frequente, representando 15,50%
do total. Por sua vez, a t√©cnica Name calling/Labeling figura como a terceira mais prevalente,
com uma representatividade de 13,45%. Quanto √† t√©cnica de persuas√£o com a
menor incid√™ncia na base de dados, observa-se que √© a Obfuscation, Intentional vagueness,
Confusion, registrando apenas 0,19% do total.

Cada texto pode ser rotulado com diferentes t√©cnicas de persuas√£o simultaneamente.
Dentro do conjunto de observa√ß√µes da base de treinamento, 3.274 foram identificadas
com duas ou mais t√©cnicas, enquanto 2.462 foram rotuladas com apenas uma
t√©cnica. Al√©m disso, h√° 1.263 textos na base que n√£o apresentam nenhuma t√©cnica de persuas√£o
em seu conte√∫do. A Figura 4 a seguir ilustra a distribui√ß√£o do n√∫mero de textos
em rela√ß√£o ao total de t√©cnicas aplicadas.

![Figura4 (Gr√°fico 2)](https://github.com/user-attachments/assets/c8ca6ddf-249a-48a8-bb85-a041b153ae70)

Uma an√°lise da distribui√ß√£o das palavras presentes nos textos dos memes tamb√©m pode ajudar a entender o comportamento de conte√∫do persuasivo e n√£o persuasivo. Como
a base possui uma alta quantidade de observa√ß√µes e, por consequ√™ncia, uma alta quantidade
de palavras, uma nuvem de palavras pode ilustrar a import√¢ncia e frequ√™ncia das
palavras na base. Para isso, foram desconsideradas as stopwords, que s√£o palavras que n√£o
v√£o trazer informa√ß√£o de fato sobre o conte√∫do presente, tais como artigos e pronomes
(MOREIRA, 2023). A Figura 5 a seguir exibe a nuvem de palavras de toda a base.

![Figura5 nuvem de palavras - base total](https://github.com/user-attachments/assets/ec0e0150-fa0a-465f-b540-ed9c702c9d2d)

De acordo com a nuvem de palavras para a base inteira, temos o destaque das
palavras ‚ÄúTrump‚Äù, ‚Äúpresident‚Äù, ‚Äúpeople‚Äù e ‚ÄúAmerica‚Äù. S√£o palavras que podem indicar a
forte presen√ßa de conte√∫do pol√≠tico na base. Ainda √© poss√≠vel ver mais termos relacionados
√† pol√≠tica, ainda com uma frequ√™ncia superior √† outras palavras da base, tais como
‚ÄúBiden‚Äù, ‚ÄúObama‚Äù, ‚Äúvote‚Äù, ‚ÄúDemocrat‚Äù, ‚ÄúRepublican‚Äù, ‚Äúgovernment‚Äù, ‚ÄúRussia‚Äù, ‚ÄúPutin‚Äù,
entre outras.

Em uma an√°lise mais detalhada, podemos tamb√©m analisar as nuvens de palavras
exclusivamente para textos classificados como propaganda e para textos classificados
como n√£o-propaganda, a fim de tentar identificar poss√≠veis diferen√ßas entre elas. A Figura
6 a seguir exibe a nuvem de palavras para os memes que foram rotulados como
n√£o-propaganda, ou seja, onde n√£o h√° t√©cnicas de persuas√£o sendo aplicadas.

![Figura6 nuvem de palavras - n√£o-propaganda](https://github.com/user-attachments/assets/3992f247-4c76-4fc9-ad91-0cb56ee63810)

A presen√ßa de conte√∫do politico tamb√©m d√° ind√≠cios de ser forte, conforme a nuvem
de palavras para os memes classificados como n√£o-propaganda. Palavras como ‚ÄúTrump‚Äù,
‚ÄúPresident‚Äù, ‚ÄúUkraine‚Äù, ‚ÄúRussia‚Äù e ‚ÄúBiden‚Äù se destacam. A maior diferen√ßa aparente em
rela√ß√£o √† base total √© o crescimento da palavra ‚ÄúUkraine‚Äù, se referindo ao pa√≠s da Ucr√¢nia.

De forma a expandir a an√°lise, a Figura 7 exibe a nuvem de palavras para os
memes rotulados como propaganda, ou seja, com conte√∫do persuasivo.

Novamente vemos uma forte presen√ßa de conte√∫do pol√≠tico, com palavras como
‚ÄúTrump‚Äù, ‚ÄúAmerica‚Äù, ‚Äúpeople‚Äù, ‚Äúpresident‚Äù, ‚Äúgovernment‚Äù, ‚Äúcountry‚Äù, entre outros. Entretanto,
diferente do que ocorre com os textos que n√£o s√£o propaganda, √© poss√≠vel identificar
xingamentos e palavr√µes neste caso, ainda que em frequ√™ncia menor do que as
palavras de maior destaque. Palavras relacionadas √† viol√™ncia e atos violentos tamb√©m podem ser identificadas.

![Figura7 nuvem de palavras - propaganda](https://github.com/user-attachments/assets/83805aad-7f9b-4c8f-8801-6883364a9b01)

### Metodologia

O processo de constru√ß√£o do sistema para detec√ß√£o de persuas√£o proposto nesse
trabalho √© composto por 5 etapas:

* Pr√©-processamento.
* Engenharia de Caracter√≠sticas.
* Balanceamento da base de treino.
* Treinamento do modelo.
* Teste e avalia√ß√£o do modelo.

#### Pr√©-processamento

Em um primeiro momento, foi realizado o pr√©-processamento dos textos das bases
de treino e teste. O passo inicial foi a remo√ß√£o das `stopwords` utilizando a biblioteca
`spaCy` do Python. Para a l√≠ngua inglesa, a biblioteca `spaCy` considera uma lista de
326 palavras como stopwords. A remo√ß√£o dessas palavras auxilia na an√°lise explorat√≥ria da
base e na cria√ß√£o de atributos, pois s√£o termos que podem aparecer com alta frequ√™ncia,
mas n√£o fornecem informa√ß√µes relevantes sobre o conte√∫do do texto.

Em seguida, foi realizada a `lematiza√ß√£o` das palavras. A `lematiza√ß√£o` √© uma forma
de normaliza√ß√£o das palavras, as convertendo para uma forma padr√£o (FINATTO et al.,
2024). As frases ‚Äúeu corro‚Äù e ‚Äúeles correm‚Äù, por exemplo, passariam a ser ‚Äúeu correr‚Äù e
‚Äúeles correr‚Äù, respectivamente. Da mesma forma, isto foi feito para os textos dos memes,
em ingl√™s, das bases de treino e teste. A lematiza√ß√£o √© √∫til para converter formas variantes
das palavras (plural, feminino, ger√∫ndio, etc.) para uma representa√ß√£o √∫nica e concisa.

Por fim, o processo de `tokeniza√ß√£o` foi utilizado para transformar cada texto em
um vetor de palavras. A `tokeniza√ß√£o` envolve a separa√ß√£o do texto em unidades lingu√≠sticas
m√≠nimas (`tokens`), separando as palavras por meio de delimitadores (FINATTO et
al., 2024). Neste trabalho, os espa√ßos e os sinais de pontua√ß√£o foram utilizados como
delimitadores.

De forma ilustrativa, apresenta-se a seguir um exemplo do processo de remo√ß√£o de
`stopwords`, `lematiza√ß√£o` e `tokeniza√ß√£o`. Considere a seguinte frase: `O gato pulou alto!`. O
seu pr√©-processamento se daria da seguinte forma:

* Remo√ß√£o das `stopwords`, resultando na frase: `gato pulou alto!`.
* `Lematiza√ß√£o`, resultando na frase: `gato pular alto!`.
* `Tokeniza√ß√£o`, resultando no vetor: `[‚Äúgato‚Äù, ‚Äúpular‚Äù, ‚Äúalto‚Äù, ‚Äú!‚Äù]`.

#### Engenharia de Caracter√≠sticas

Para obter atributos num√©ricos a partir dos dados textuais, foi empregada a `engenharia
de caracter√≠sticas`. A `engenharia de caracter√≠sticas` √© o ato de extra√ß√£o de atributos
dos dados brutos e a transforma√ß√£o desses atributos em formatos adequados, como vetores
num√©ricos, necess√°rios para os algoritmos de aprendizado de m√°quina (NARGESIAN et
al., 2017; ZHENG; CASARI, 2018).

De forma a obter-se um vetor num√©rico representativo do texto do meme, foram
considerados os seguintes atributos utilizados por Cruz, Rocha e Cardoso (2019), que
foram adaptados para o contexto do problema e extra√≠dos para o texto de cada meme da
base de treino:

* N√∫mero total de frases: representa o total de frases do texto do meme.
*  M√©dia de caracteres por frase: representa a m√©dia de caracteres por frase do texto
do meme, onde cada frase √© delimitada por ponto final, ponto de exclama√ß√£o ou
ponto de interroga√ß√£o.
* Vari√¢ncia de caracteres por frase: representa a vari√¢ncia de caracteres por frase do
texto do meme, utilizando a mesma delimita√ß√£o de frase do atributo (2).
* Total de caracteres: representa o total de caracteres presente em todo o texto do
meme.
* M√©dia de caracteres por palavra: representa a m√©dia de caracteres por palavra do
texto do meme.
* Vari√¢ncia de caracteres por palavra: representa a vari√¢ncia de caracteres por palavra
do texto do meme.
* Frequ√™ncia de pontua√ß√£o: representa a frequ√™ncia absoluta de todos os s√≠mbolos de
pontua√ß√£o presentes no texto do meme.
* Frequ√™ncia de letras mai√∫sculas: representa a frequ√™ncia absoluta de todas as letras
mai√∫sculas presentes no texto do meme.
* Propor√ß√£o de token sobre palavras lematizadas: representa o total de palavras lematizadas
dividido pelo total de tokens do texto do meme (‚Äúandou‚Äù e ‚Äúandei‚Äù s√£o
dois tokens diferentes, mas ao serem lematizados, ambos se tornam ‚Äúandar‚Äù).
* TF-IDF.

De forma ilustrativa, considere o seguinte texto, em portugu√™s, para passar pelo
processo de extra√ß√£o de atributos num√©ricos atrav√©s da engenharia de caracter√≠sticas:

`As Olimp√≠adas chegaram! Os atletas acabam de chegar em Paris para a maior
competi√ß√£o esportiva do mundo. O Time Brasil est√° preparado? De acordo com os
atletas, eles est√£o!`

Considerando as vari√°veis apresentadas previamente (desconsiderando o TF-IDF),
temos os seguintes atributos num√©ricos extra√≠dos:

* N√∫mero total de frases: 4.
* M√©dia de caracteres por frase: 42,25.
* Vari√¢ncia de caracteres por frase: 499,69.
* Total de caracteres: 172.
* M√©dia de caracteres por palavra: 4,79.
* Vari√¢ncia de caracteres por palavra: 7,06.
* Frequ√™ncia de pontua√ß√£o: 5.
* Frequ√™ncia de letras mai√∫sculas: 8.
* Propor√ß√£o de tokens sobre palavras lematizadas: 0,74.

Analisando o atributo `Propor√ß√£o de tokens sobre palavras lematizadas`, de mais complexo entendimento que os outros, podemos
detalhar seu processo de c√°lculo. Os `tokens` gerados para o texto formam o seguinte vetor
de palavras e pontua√ß√µes:

`["As", "Olimp√≠adas", "chegaram", "!", "Os", "atletas", "acabam", "de", "chegar", "em",
"Paris", "para", "a", "maior", "competi√ß√£o", "esportiva", "do", "mundo", ".", "O", "Time",
"Brasil", "est√°", "preparado", "?", "De", "acordo", "com", "os", "atletas", ",", "eles",
"est√£o", "!"]`

Este vetor tem o total de 34 elementos. O pr√≥ximo passo consiste em gerar um
vetor com as palavras lematizadas, que resulta no seguinte vetor de palavras e pontua√ß√µes:

`[‚Äô!‚Äô, ‚Äô,‚Äô, ‚Äô.‚Äô, ‚Äô?‚Äô, ‚ÄôBrasil‚Äô, ‚ÄôOlimp√≠adas‚Äô, ‚ÄôParis‚Äô, ‚ÄôTime‚Äô, ‚Äôacabar‚Äô, ‚Äôacordo‚Äô, ‚Äôatleta‚Äô,
‚Äôchegar‚Äô, ‚Äôcom‚Äô, ‚Äôcompeti√ß√£o‚Äô, ‚Äôde‚Äô, ‚Äôde o‚Äô, ‚Äôele‚Äô, ‚Äôem‚Äô, ‚Äôesportivo‚Äô, ‚Äôestar‚Äô, ‚Äôgrande‚Äô,
‚Äômundo‚Äô, ‚Äôo‚Äô, ‚Äôpara‚Äô, ‚Äôpreparado‚Äô]`

No vetor lematizado h√° um total de 25 elementos. Neste caso, n√£o h√° repeti√ß√µes.
Desta forma, o atributo √© calculado por 25/34, resultado no valor de 0,74.

#### TF-IDF

Uma das formas a ser utilizada para a extra√ß√£o de atributos a partir do conte√∫do
dos textos ser√° a `Matriz Documento-Termo (Document-Term Matrix - DTM)` com pesos
`TF-IDF`. Para explicar o `TF-IDF`, ser√° apresentado um exemplo de como essa medida
√© usada no contexto de busca de documentos na Internet. Para ordenar documentos em
resposta √† uma consulta realizada, h√° duas premissas que podem ser utilizadas:

* Documentos que cont√©m mais vezes os termos da consulta ter√£o mais chances de
serem relacionados a ela e, ent√£o, serem relevantes.
* Os termos mais raros na cole√ß√£o de documentos s√£o √∫teis para a diferencia√ß√£o de
conte√∫do nos documentos (MOREIRA, 2023).

Por exemplo, se uma pessoa decide pesquisar sobre artigos de not√≠cias do cen√°rio
pol√≠tico nos EUA em um corpus de documentos (um site de not√≠cias, por exemplo), alguns
termos ser√£o mais relevantes que outros. Palavras como ‚ÄúBiden‚Äù ou ‚ÄúCasa Branca‚Äù ser√£o
termos √∫teis para a pesquisa, enquanto termos como ‚Äúbasquete‚Äù ou ‚Äúprevis√£o do tempo‚Äù
j√° n√£o ter√£o tanta utilidade.

O `TF-IDF` e a `DTM` s√£o usados n√£o apenas para recupera√ß√£o da informa√ß√£o (busca
de documentos), mas tamb√©m em problemas de classifica√ß√£o. Na `DTM`, cada linha representa
um documento em uma cole√ß√£o de documentos e cada coluna representa uma palavra
ou grupo de palavras, onde cada c√©lula da matriz representa o peso do termo no documento
(JURAFSKY; MARTIN, 2024e). Para atribuir pesos aos termos em rela√ß√£o aos documentos,
√© muito comum utilizar a medida `TF-IDF`, onde `TF` significa ‚Äúterm-frequency‚Äù
(frequ√™ncia do termo) e `IDF` significa ‚Äúinverse document-frequency‚Äù (frequ√™ncia inversa do
termo) (MOREIRA, 2023). A medida `TF-IDF` √©, ent√£o, o produto de `TF` e `IDF`. 

O c√°lculo dos pesos `TF-IDF` foi realizado utilizando a biblioteca `Scikit-learn`, no
`Python`. A biblioteca calcula o termo `TF(ùë°,ùëë)` como sendo a frequ√™ncia absoluta em que o
termo ùë° aparece no documento ùëë. O componente `IDF` tem o objetivo de dar um peso maior aos termos mais raros,
pois eles s√£o √∫teis para discriminar o conte√∫do dos documentos (MOREIRA, 2023). Portanto,
quanto mais raro o termo for no corpus, maior ser√° o valor `IDF`.

Neste trabalho, cada documento corresponde a um texto de meme, e o corpus √©
composto pelo conjunto de todos os textos de memes presentes na base de dados. Nos
experimentos, os termos ser√£o representados de duas formas distintas:

* Os `50 unigramas` mais frequentes.
* Os `50 bigramas` mais frequentes.

Os `unigramas` e `bigramas` s√£o dois exemplos de `n-gramas`. O `n-grama` √© uma sequ√™ncia
de n palavras (JURAFSKY; MARTIN, 2024b). Portanto, o `unigrama` √© uma sequ√™ncia
de uma palavra e o `bigrama` √© uma sequ√™ncia de duas palavras.

#### Balanceamento da Base

Bases desbalanceadas podem levar o modelo a favorecer previs√µes na classe majorit√°ria (CRUZ; ROCHA; CARDOSO, 2019). Como a base de treino cont√©m 78% de suas observa√ß√µes
classificadas como propaganda, tem-se um caso em que os modelos podem favorecer a
previs√£o dos textos da base de teste dessa forma. Portanto, com o objetivo de retirar
essa tend√™ncia de classifica√ß√£o, ser√£o aplicadas duas formas distintas de balanceamento:
`undersampling` e `oversampling`.

Ao se utilizar dados do mundo real, classes desbalanceadas podem ser esperadas.
Se o grau de desbalanceamento dos dados para a classe majorit√°ria for algo extremo ent√£o
o classificador pode produzir uma alta acur√°cia na previs√£o, dado que o modelo prev√™ a
maioria das inst√¢ncias como pertencentes √† classe majorit√°ria (LEEVY et al., 2018).

O m√©todo `undersampling` consiste na redu√ß√£o da quantidade de observa√ß√µes da
classe majorit√°ria. A forma mais popular para a aplica√ß√£o de `undersampling`, que tamb√©m
ser√° utilizada neste trabalho, √© o `undersampling` aleat√≥rio. O m√©todo consiste em remover
observa√ß√µes da classe majorit√°ria, aleatoriamente, at√© que a base de dados alcance o
balanceamento entre as classes.

Por outro lado, o m√©todo `oversampling` consiste na gera√ß√£o de novas amostras
de observa√ß√µes pertencentes √† classe minorit√°ria. A forma mais comum de utiliza√ß√£o
do m√©todo, que tamb√©m ser√° utilizada nesse trabalho, √© atrav√©s da gera√ß√£o de novas
observa√ß√µes a partir de uma amostragem com reposi√ß√£o da classe minorit√°ria. Desta
forma, observa√ß√µes aleat√≥rias da classe minorit√°ria s√£o replicadas na base at√© que se
tenha o balanceamento entre as classes.

Os dois m√©todos de balanceamento ser√£o aplicados na base de treino, de forma a
balancear as classes para tentar obter um melhor desempenho dos modelos de classifica√ß√£o.
Resultados emp√≠ricos de trabalhos relevantes apontam que o m√©todo de `oversampling`
aleat√≥rio alcan√ßa melhores resultados do que o m√©todo de `undersampling` aleat√≥rio (LEEVY
et al., 2018).

#### T√©cnicas de Classifica√ß√£o

##### √Årvores de Decis√£o

As `√°rvores de decis√£o` s√£o um m√©todo aprendizado n√£o param√©trico usado para
classifica√ß√£o e regress√£o. De acordo com a biblioteca `Scikit-learn`, o objetivo √© criar um
modelo que preveja o valor de uma vari√°vel alvo, aprendendo regras de decis√£o simples
inferidas a partir dos dados. Uma vantagem deste algoritmo √© a facilidade na sua interpreta√ß√£o.

As `√°rvores de decis√£o` s√£o constru√≠das atrav√©s da an√°lise de uma base de treino, no
qual a classifica√ß√£o de cada observa√ß√£o √© conhecida, sendo utilizada posteriormente para
classificar dados novos e desconhecidos (KINGSFORD; SALZBERG, 2008).

De acordo com Ali et al. (2012), a ideia do algoritmo veio a partir da estrutura de
uma √°rvore real, que √© composta por raiz e n√≥s, sendo que os n√≥s seriam as ramifica√ß√µes
e os locais onde elas se dividem. A √°rvore de decis√£o, ent√£o, √© constru√≠da a partir dos n√≥s
e os ramos s√£o representados pelos segmentos que conectam os n√≥s. Ela come√ßa da raiz e se move para baixo. O n√≥ onde as ramifica√ß√µes se encerram √© conhecido como folha.
Cada n√≥ representa uma certa caracter√≠stica enquanto os ramos representam uma gama
de valores. A Figura a seguir apresenta um exemplo de uma `√Årvore de Decis√£o` que
classifica um cliente como poss√≠vel comprador de carro importado com base em sua renda
e idade (SILVA; GON√áALVES, 2021).

![Figura8 Exemplo_AD](https://github.com/user-attachments/assets/2f4adf59-69d1-4b7a-90c2-6a3755d7b851)

Uma `√Årvore de Decis√£o` √© formada por um conjunto de regras de classifica√ß√£o,
uma vez que existe sempre um √∫nico caminho da raiz para cada folha, onde o caminho
representa uma express√£o l√≥gica da regra utilizada para classificar um objeto (SILVA;
GON√áALVES, 2021). Por exemplo, as regras da Figura anterior para classificar o cliente como
poss√≠vel comprador de carro importado s√£o:

* SE (renda = ‚Äúalta‚Äù), ENT√ÉO (poss√≠vel comprador = ‚Äúsim‚Äù).
* SE (renda = ‚Äúm√©dia‚Äù) e (idade > 30), ENT√ÉO (poss√≠vel comprador = ‚Äúsim‚Äù).

O algoritmo `CART` (BREIMAN et al., 1984) √© um dos mais populares para a
gera√ß√£o de √°rvore de decis√£o. Este algoritmo realiza a decis√£o de como dividir a √°rvore 
atrav√©s do `√çndice de Gini`, que ser√° utilizado para montar a √°rvore atrav√©s de decis√µes
bin√°rias. Portanto, cada n√≥ gerado ter√° duas ramifica√ß√µes.

Como o algoritmo `CART` realiza apenas divis√µes bin√°rias em cada n√≥, sempre ser√£o
feitas divis√µes que resultem em duas ramifica√ß√µes (BREIMAN et al., 1984). Suponha que
um atributo preditivo ‚Äútempo‚Äù tenha as seguintes classifica√ß√µes poss√≠veis: sol, chuva e
nublado. Neste caso, o algoritmo `CART` faria parti√ß√µes da seguinte forma: {sol, chuva},
{sol, nublado}, {chuva, nublado}, {sol}, {chuva} e {nublado}. Ent√£o, seria calculado o
`√çndice de Gini` para cada combina√ß√£o poss√≠vel entre as reparti√ß√µes. Dessa forma, √© feita a
soma ponderada de cada parti√ß√£o.

#### Floresta Aleat√≥ria (Random Forest)

O m√©todo `Floresta Aleat√≥ria` √© uma combina√ß√£o de √°rvores de decis√£o em que
cada √°rvore depende de valores de um vetor aleat√≥rio amostrado, em que os vetores s√£o
independentes e identicamente distribu√≠dos, sendo que o k-√©simo vetor gerado governa a
k-√©sima √°rvore de decis√£o (BREIMAN, 2001).

Segundo descrito por Ali et al. (2012), cada √°rvore √© gerada a partir dos seguintes
passos:

* Gerando uma amostra aleat√≥ria com reposi√ß√£o e de tamanho ùëÅ, se o n√∫mero de
casos na base de treinamento for igual a ùëÅ, da base de dados. Essa amostra √©
usada como treinamento para a √°rvore de decis√£o.
* Sendo ùëë o valor total de atributos preditivos, ùëö atributos s√£o selecionados aleatoriamente
de ùëë, sendo que ùëö ‚â™ ùëë. A melhor divis√£o dos ùëö atributos selecionados
√© utilizada para a divis√£o do n√≥. Durante o processo de gera√ß√£o de √°rvores aleat√≥rias,
o valor de ùëö √© constante.
* Cada √°rvore gerada cresce o m√°ximo poss√≠vel.

#### Regress√£o Log√≠stica

A `Regress√£o Log√≠stica` √© um classificador probabil√≠stico, sendo uma das ferramentas
anal√≠ticas mais importantes das ci√™ncias sociais e naturais (JURAFSKY; MARTIN,
2024a). No `Processamento de Linguagem Natural`, ela √© o algoritmo de aprendizado de m√°quina
supervisionado b√°sico para classifica√ß√£o e tamb√©m tem uma rela√ß√£o muito pr√≥xima
com redes neurais (JURAFSKY; MARTIN, 2024a).

Conforme Jurafsky e Martin (2024a) destacam, o principal prop√≥sito da regress√£o
log√≠stica bin√°ria reside em tornar um classificador capaz de tomar uma decis√£o dicot√¥mica
sobre a classe de uma nova observa√ß√£o. Para isso, temos o conjunto ùëã = {ùëã1,ùëã2, . . . ,ùëãùëë}
de atributos num√©ricos para cada observa√ß√£o ùë•, sendo que o output ùë¶ do classificador ser√°
igual a 1 quando a observa√ß√£o for classificada como parte da classe e 0 caso contr√°rio.
Neste trabalho, foi definido que o valor 1 significa texto com persuas√£o e 0 significa texto
sem persuas√£o. Queremos saber a probabilidade condicional ùëù(ùë¶ = 1|ùë•). Caso essa seja
maior que 0,5, ent√£o teremos a classifica√ß√£o ùë¶ = 1 e, caso contr√°rio, ùë¶ = 0.

Ainda segundo Jurafsky e Martin (2024), a `regress√£o log√≠stica` resolve essa tarefa
aprendendo um vetor de pesos (coeficientes) e um termo de vi√©s (intercepto). Cada peso
ùë§ùëñ √© um n√∫mero real associado ao atributo preditivo ùëãùëñ. Ent√£o, para tomar uma decis√£o,
primeiro multiplica-se cada ùëãùëñ pelo peso ùë§ùëñ, soma-se o resultado e adiciona-se o termo de
vi√©s ùëè, resultando em um valor ùëß que expressa a soma ponderada para a classe.

O vetor de pesos w vai indicar o qu√£o importante cada atributo √© para a classifica√ß√£o.
O valor ùëß tamb√©m pode ser representado pelo produto escalar dos vetores w e
X. O produto escalar de dois vetores a e b pode ser escrito como a ¬∑ b e ser√° a soma
dos produtos dos elementos correspondentes de cada vetor.

Para representar ùëß como uma probabilidade, a fun√ß√£o `sigmoide` (tamb√©m chamada
de fun√ß√£o log√≠stica), apresentada na Figura a seguir, √© introduzida e apresentada graficamente, de forma a termos valores entre 0 e 1. Como cada um dos pesos possuem
valores reais, o valor de ùëß na pode variar de ‚àí‚àû at√© +‚àû.

![Figura9 funcao sigmoide](https://github.com/user-attachments/assets/8a2e4316-f28e-4251-856f-c85315c43f07)

O processo de treinamento da regress√£o log√≠stica envolve uma fun√ß√£o objetiva para
aprendizado, que visa minimizar os erros e otimizar o desempenho do modelo. A fun√ß√£o
objetiva utilizada √© a perda de `entropia cruzada`. A fun√ß√£o ùêø(^ùë¶, ùë¶) mede o qu√£o pr√≥ximo
^ùë¶, a classe estimada, est√° de ùë¶, a classe verdadeira (JURAFSKY; MARTIN, 2024a).
A otimiza√ß√£o da fun√ß√£o de perda ocorre atrav√©s do `gradiente descendente`. Seu objetivo
√© encontrar o conjunto de pesos que ir√° minimizar a fun√ß√£o de perda (JURAFSKY;
MARTIN, 2024a). O `gradiente descendente` √© um m√©todo que encontra o m√≠nimo de uma fun√ß√£o
ao descobrir, no espa√ßo de par√¢metros ùúÉ, a dire√ß√£o em que a inclina√ß√£o da fun√ß√£o est√°
aumentando de forma mais acentuada. Ent√£o, ele se move na dire√ß√£o oposta (JURAFSKY;
MARTIN, 2024a).

### M√©tricas de Avalia√ß√£o

Uma vez que o modelo √© treinado, o pr√≥ximo passo consiste em obter as suas
predi√ß√µes em uma base de teste. A base de teste √© composta por objetos rotulados, mas
que n√£o foram utilizados na constru√ß√£o do modelo. A partir das predi√ß√µes que o modelo
faz na base de teste, tona-se poss√≠vel construir uma matriz de confus√£o. A avalia√ß√£o
dos classificadores se dar√° pela acur√°cia, precis√£o, recall e F1-Score, m√©tricas de avalia√ß√£o
calculadas a partir da matriz de confus√£o (JURAFSKY; MARTIN, 2024c). A estrutura da
matriz de confus√£o utilizada neste trabalho √© apresentada na Tabela a seguir, onde cada elemento
da matriz corresponde √† frequ√™ncia absoluta de classifica√ß√µes. A matriz de confus√£o possui
as seguintes classifica√ß√µes:

* `VN`: Verdadeiro Negativo (classificou que n√£o era persuasivo e acertou).
* `FP`: Falso Positivo (classificou que era persuasivo e errou).
* `FN`: Falso Negativo (classificou que n√£o era persuasivo e errou).
* `VP`: Verdadeiro Positivo (classificou que era persuasivo e acertou).

![estrutura_matriz_confusao](https://github.com/user-attachments/assets/2d728855-d3a2-4c76-b364-0c27e69ba182)

A `acur√°cia` mede a propor√ß√£o de predi√ß√µes corretas feita pelo modelo, ou seja,
a quantidade de exemplos que foram corretamente classificados em rela√ß√£o ao total de
exemplos.

![formula_acuracia](https://github.com/user-attachments/assets/56c2ae13-4636-4f41-8c3c-b1805ad27711)

A `precis√£o` indica a propor√ß√£o de exemplos positivos classificados corretamente
pelo modelo em rela√ß√£o a todos os exemplos que o modelo classificou como positivos.

![formula_precisao](https://github.com/user-attachments/assets/5402264d-4453-4b44-8cc7-e51df7bbf385)

O `recall` mede a propor√ß√£o de exemplos positivos que foram corretamente identificados
pelo modelo em rela√ß√£o a todos os exemplos que s√£o realmente positivos.

![formula_recall](https://github.com/user-attachments/assets/5f7f6eea-b743-43bb-9d76-daac3c0e64c9)

Por fim, a medida `F1-Score` √© m√©dia harm√¥nica da precis√£o e do recall, fornecendo
uma m√©trica que balanceia precis√£o e recall.

![formula_f1score](https://github.com/user-attachments/assets/fbeee373-dace-4f5c-a202-2757507df017)


### Resultados

Neste cap√≠tulo s√£o apresentados os resultados obtidos a partir dos experimentos
realizados conforme a metodologia previamente descrita. Os experimentos foram realizados
com o objetivo de criar e avaliar diferentes modelos de classifica√ß√£o para detectar a
presen√ßa de conte√∫do persuasivo no texto do meme. Para isso, a base de treino foi utilizada
para treinar os classificadores e a base de teste foi utilizada para estimar o desempenho
preditivo dos modelos.

Para resolver o problema do desbalanceamento da base, utilizou-se os m√©todos
de balanceamento de base descritos na metodologia. Foram utilizados os atributos preditivos
apresentados na se√ß√£o metodol√≥gica, que foram obtidos atrav√©s da engenharia de
caracter√≠sticas. A partir desses atributos, diferentes combina√ß√µes foram realizadas nos experimentos.
A seguir, apresentam-se os atributos utilizados em cada um dos experimentos.

* Atributos utilizados por Cruz et al. (2019), desconsiderando a medida TF-IDF.
* Atributos utilizados por Cruz et al. (2019) com a medida TF-IDF para os 50
bigramas mais frequentes.
* Atributos utilizados por Cruz et al. (2019) com a medida TF-IDF para os 50
unigramas mais frequentes.

#### Resultados Gerais

No `experimento 1` podemos obter o efeito isolado dos atributos gerados pela engenharia
de caracter√≠sticas, sem considerar o TF-IDF. Os experimentos 2 e 3 nos fornecem
o efeito conjunto dos atributos e a medida TF-IDF, com bigramas e unigramas, respectivamente.
A Tabela a seguir exibe os resultados obtidos no `experimento 1`, onde n√£o foi
inclu√≠da a medida TF-IDF.

![tabela_exp1](https://github.com/user-attachments/assets/26f181c9-ceba-4279-8d0b-99d8899dbde0)

No `experimento 1`, ao se utilizar `undersampling`, a `Floresta Aleat√≥ria` se destaca
com uma acur√°cia de 0,6940 e um F1-Score de 0,7916, superando tanto a `√Årvore de
Decis√£o` quanto a `Regress√£o Log√≠stica`. A alta precis√£o, de 0,9366, indica que a `Regress√£o
Log√≠stica` tem um baixo √≠ndice de falsos positivos.

No cen√°rio de `oversampling`, todos os classificadores apresentam uma melhoria na
acur√°cia, recall e F1-Score. Novamente, a `Floresta Aleat√≥ria` lidera com uma acur√°cia de
0,8020 e um F1-Score de 0,8833. A `√Årvore de Decis√£o` tamb√©m apresenta bons resultados,
com uma acur√°cia de 0,7730, precis√£o de 0,8791 e um F1-Score de 0,8638. A `Regress√£o Log√≠stica`, embora tenha melhorado em rela√ß√£o ao cen√°rio com `undersampling`, ficou atr√°s
com uma acur√°cia de 0,6660 e um F1-Score de 0,7668.

Em uma an√°lise global do `experimento 1`, a `Floresta Aleat√≥ria` apresenta os maiores
valores de acur√°cia, recall e F1-Score no cen√°rio de `oversampling`. A `√Årvore de Decis√£o`,
que √© um m√©todo mais simples, alcan√ßou resultados pr√≥ximos dos resultados obtidos pela
`Floresta Aleat√≥ria` com o `oversampling`. Esse √© um ponto relevante, dado que a `√Årvore de
Decis√£o` gera um modelo interpret√°vel e de f√°cil entendimento. J√° a `Regress√£o Log√≠stica`
vence na precis√£o, no cen√°rio de `undersampling`. O experimento ainda foi realizado em um
cen√°rio com balanceamento `SMOTE` (CHAWLA et al., 2002), t√©cnica de balanceamento
bastante tradicional que gera observa√ß√µes sint√©ticas da classe minorit√°ria. Por√©m, esta
t√©cnica obteve resultados inferiores e foi desconsiderada deste trabalho.

A Tabela a seguir apresenta os resultados do `experimento 2`, incluindo a medida
TF-IDF com os 50 bigramas mais frequentes. Neste experimento, no cen√°rio com undersampling, a `Floresta Aleat√≥ria` obt√©m
a maior acur√°cia, recall e F1-Score. Contudo, com exce√ß√£o da `Regress√£o Log√≠stica`, os
desempenhos dos modelos foram inferiores ao cen√°rio com `oversampling`. A `Regress√£o
Log√≠stica` vence na precis√£o, com um valor de 0,9427, apenas um pouco maior do que o
obtido no `experimento 1`.

Quando o `oversampling` √© aplicado, a `√Årvore de Decis√£o` e a `Floresta Aleat√≥ria` apresentam fortes aumentos de acur√°cia e F1-Score. Neste cen√°rio, a `√Årvore de Decis√£o`
alcan√ßa um valor de 0,7870 na acur√°cia e 0,8719 no F1-Score. J√° a `Floresta Aleat√≥ria`,
0,7970 e 0,8810, respectivamente, o que a coloca como o classificador com os maiores
valores nessas duas m√©tricas. A `Regress√£o Log√≠stica` obt√©m valores levemente menores na
acur√°cia e F1-Score, com 0,6630 e 0,7622, respectivamente. Na precis√£o, ela consegue uma
leve melhora, atingindo o valor de 0,9424.

![tabela_exp2](https://github.com/user-attachments/assets/320cf52c-b35b-4378-95d2-e7864c316e7b)

Analisando todo o `experimento 2` conjuntamente, destacam-se os resultados obtidos
pela `Floresta Aleat√≥ria` no cen√°rio com `oversampling`. Ela obteve uma acur√°cia de
0,7980, um recall de 0,8863 e um F1-Score de 0,8810, sendo esses os maiores valores dessas
m√©tricas no experimento. A `Regress√£o Log√≠stica` se destaca com a maior precis√£o de todas,
com um valor de 0,9427, no cen√°rio com `undersampling`.

A Tabela a seguir apresenta os resultados do `experimento 3`, incluindo a medida
TF-IDF com os 50 unigramas mais frequentes. No `experimento 3`, ao utilizar do `undersampling`, a acur√°cia, recall e F1-Score de
todos os modelos s√£o inferiores em rela√ß√£o ao cen√°rio de `oversampling` A precis√£o dos
modelos, contudo, foi superior. A `Regress√£o Log√≠stica`, novamente, apresenta destaque
com sua alta precis√£o de 0,9472.

![tabela_exp3](https://github.com/user-attachments/assets/638174f2-a937-430c-b07d-248ba5fc3afc)

Com a aplica√ß√£o do balanceamento por `oversampling`, todos os classificadores apresentam
melhoria na acur√°cia, recall e F1-Score. Novamente, a `Floresta Aleat√≥ria` demonstra um desempenho superior em rela√ß√£o aos outros classificadores, atingindo a maior
acur√°cia, com 0,8130, e o maior F1-Score, com 0,8894. J√° a `√Årvore de Decis√£o`, dessa vez,
ultrapassa a `Regress√£o Log√≠stica` e atinge o segundo maior F1-Score entre os classificadores,
com um total de 0,8680 contra 0,7700 da `Regress√£o Log√≠stica`. Por√©m, novamente,
a `Regress√£o Log√≠stica` se destaca com sua alta precis√£o, obtendo um valor de 0,9433,
levemente inferior ao que obteve no cen√°rio com `undersampling`.

Analisando o `experimento 3` como um todo, o maior destaque vai para a `Floresta
Aleat√≥ria` com balanceamento por `oversampling`. Ela apresenta os maiores valores de acur√°cia,
recall e F1-Score para todo o `experimento 3`, se destacando com o valor de 0,8894
na medida F1-Score.

Observando todos os 3 experimentos, podemos ver resultados muitos pr√≥ximos entre
eles, com a `Floresta Aleat√≥ria` apresentando os melhores resultados no cen√°rio com
`oversampling` do `experimento 3`. Ela alcan√ßou uma acur√°cia de 0,8130, um recall de 0,8910
e um F1-Score de 0,8894. Foram os maiores valores para essas m√©tricas entre todos os
classificadores em todos os experimentos realizados. Por√©m, ao levarmos em considera√ß√£o
a proximidade dos resultados, √© interessante considerar o `experimento 1` como o melhor
entre eles, pois trata-se de um cen√°rio em que os atributos gerados pela engenharia de
caracter√≠sticas s√£o de maior simplicidade e melhor entendimento. Al√©m disso, embora a
`Floresta Aleat√≥ria` apresente o melhor desempenho, tamb√©m √© v√°lido notar que os resultados
com `√Årvore de Decis√£o` foram bastante pr√≥ximos. A `√Årvore de Decis√£o` √© um modelo interpret√°vel e √© de f√°cil entendimento o processo feito por ela para classificar uma nova
observa√ß√£o. Ent√£o, por uma quest√£o de maior poder interpretativo, seus resultados neste
trabalho possuem um destaque em rela√ß√£o aos outros. J√° a `Regress√£o Log√≠stica` obteve
a maior precis√£o de todos os experimentos no cen√°rio com `undersampling`, tamb√©m no
`experimento 3`, alcan√ßando um valor de 0,9472.

#### Compara√ß√£o com Modelos Gerados sem Balanceamento de Classes

Os resultados apresentados na se√ß√£o anterior, onde foram aplicadas t√©cnicas de
balanceamento de classes, evidenciam uma tentativa de melhoria dos resultados originais,
sem balanceamento. Uma base desbalanceada pode levar o modelo a favorecer previs√µes na classe
majorit√°ria (CRUZ; ROCHA; CARDOSO, 2019), sendo esse o caso da base de treino
utilizada neste trabalho.

O `experimento 1`, com os atributos gerados pela engenharia de caracter√≠sticas e
sem considerar a medida TF-IDF, alcan√ßa resultados pr√≥ximos aos outros experimentos.
Por√©m, √© o experimento de mais f√°cil entendimento, pois s√£o atributos facilmente interpret√°veis
que foram extra√≠dos do texto. Portanto, esse experimento ser√° utilizado como base
de compara√ß√£o ao cen√°rio sem balanceamento. A Tabela a seguir exibe os resultados do
`experimento 1` sem nenhum balanceamento de base.

![tab_exp1_desbalanceado](https://github.com/user-attachments/assets/3cced60c-a8ee-4487-a59a-b3221de92175)

Ao analisar os resultados e comparar com os cen√°rios onde `undersampling` e `oversampling`
foram aplicados, pode se ter a conclus√£o de que o cen√°rio sem balanceamento
algum √© melhor e mais promissor, dado que os valores de acur√°cia, recall e F1-Score s√£o
superiores. Contudo, pode se tratar de uma interpreta√ß√£o equivocada. Neste cen√°rio, √© importante
analisar n√£o s√≥ os valores das m√©tricas, mas o contexto em que esse experimento
ocorreu.

Ao realizar o experimento em uma base que n√£o passou pelo processo de `undersampling`
ou `oversampling`, h√° um forte desbalanceamento. A base de treino possui um
total de 78% das observa√ß√µes com textos de memes classificados como persuasivos, contra
22% de textos n√£o persuasivos. Conforme apontado por Cruz, Rocha e Cardoso (2019),
isso tende a favorecer previs√µes na classe majorit√°ria, nesse caso, criando um vi√©s para
classificar novos textos de memes como persuasivos.

Assim como a base de treino, a base de teste tamb√©m possui a maior parte das
observa√ß√µes com textos persuasivos, representando 84% das observa√ß√µes. Essa alta propor√ß√£o,
aliada com um vi√©s dos modelos para classificar textos como persuasivos, tendem
a levar a um cen√°rio em que os modelos ter√£o um alto √≠ndice de acertos. Por√©m, dado o
contexto, isso n√£o representa um bom resultado.

De forma a ilustrar esta an√°lise, a Tabela a seguir apresenta a matriz de confus√£o
gerada para a `Regress√£o Log√≠stica`, modelo com o maior F1-Score no cen√°rio sem
balanceamento.

![matriz_confusao_sem_balanceamento](https://github.com/user-attachments/assets/9b9eff9a-4750-4b89-8adb-1da321cfb264)

Na matriz de confus√£o, as linhas representam a classe verdadeira e as colunas
representam a classe predita. Como se pode observar, quase todas as observa√ß√µes da base
de teste foram preditas como texto persuasivo. Com 84% da base sendo de fato texto
persuasivo, a quantidade de acertos √© bastante alta. Por√©m, isso n√£o indica um bom
modelo, mas apenas evidencia o vi√©s gerado pela base n√£o balanceada. A Tabela 9 a
seguir evidencia a forte diferen√ßa na matriz de confus√£o para a `Regress√£o Log√≠stica` no
cen√°rio com balanceamento por `oversampling`. Foi escolhido o cen√°rio com `oversampling`
para a compara√ß√£o por este ter apresentado os melhores resultados.

![matriz_confusao_RL_oversampling](https://github.com/user-attachments/assets/28d0742a-6585-4b73-816e-341c58c86657)

Portanto, embora apresente m√©tricas elevadas, conclui-se que n√£o se trata de uma
boa classifica√ß√£o e que o balanceamento da base √© uma importante estrat√©gia para se ter
resultados mais promissores e confi√°veis.

#### An√°lise da Import√¢ncia dos Atributos com √Årvore de Decis√£o

Os modelos treinados com `√Årvore de Decis√£o` obtiveram um desempenho preditivo
muito pr√≥ximo da `Floresta Aleat√≥ria`. Diferentemente da `Floresta Aleat√≥ria`, a `√Årvore de
Decis√£o` gera um modelo diretamente interpret√°vel, em uma estrutura gr√°fica, de forma √©
apresentado de forma clara o que levou o modelo a fazer uma determinada classifica√ß√£o.
Esta se√ß√£o tem por objetivo analisar a import√¢ncia dos atributos da `√Årvore de Decis√£o`
do `experimento 1`, no cen√°rio com `oversampling`. Este experimento foi escolhido pela
maior simplicidade nos atributos utilizados e por seu bom desempenho. O cen√°rio com
`oversampling` foi escolhido por apresentar os melhores resultados do experimento.

A `√Årvore de Decis√£o` gerada possui diferentes regras, onde cada regra leva a classifica√ß√£o
do texto do meme como persuasivo ou n√£o persuasivo. Uma elevada quantidade
de regras foi gerada, onde 1.263 regras possuem 100% de confian√ßa, ou sejam, classificam
perfeitamente um texto como persuasivo ou n√£o persuasivo. Dado o elevado n√∫mero de
regras definidas, ser√£o apresentadas as duas regras com maior cobertura para os textos
persuasivos e as duas regras com maior cobertura para os textos n√£o persuasivos, todas
com 100% de confian√ßa.

Como a an√°lise est√° sendo feita para o cen√°rio com `oversampling`, √© importante
lembrar que estamos lidando com uma base de treino que cont√©m mais observa√ß√µes do
que teria sem a aplica√ß√£o dessa t√©cnica de balanceamento. Nesse contexto, a base de
treino possui um total de 11.472 textos de memes, devido √† replica√ß√£o de textos da classe
minorit√°ria.

Primeiramente, apresentam-se as regras com maior cobertura para a classifica√ß√£o
de textos como persuasivos. A primeira regra cobre em 525 textos persuasivos, enquanto
a segunda, cobre 187 textos persuasivos, todos provenientes da base de treino.

* SE (total de caracteres > 125,5) e (4,005 < m√©dia de caracteres por palavra
<= 5,544) e (m√©dia de caracteres por frase < 27,829) e (1,349 < vari√¢ncia de
caracteres por palavra <= 7,933) e (3,5 < frequ√™ncia de pontua√ß√£o <= 9,5) e
(frequ√™ncia de letras mai√∫sculas > 6,5) e (propor√ß√£o de tokens sobre palavras
lematizadas > 0,489), ENT√ÉO (Texto = ‚ÄúPersuasivo‚Äù).
* SE (total de caracteres > 325,5) e (m√©dia de caracteres por palavra > 4,005)
e (m√©dia de caracteres por frase > 27,829) e (vari√¢ncia de caracteres por frase
<= 51.948,834) e (frequ√™ncia de pontua√ß√£o > 9,5) e (propor√ß√£o de tokens sobre
palavras lematizadas > 0,489), ENT√ÉO: (Texto = ‚ÄúPersuasivo‚Äù).

Por fim, apresentam-se as regras com maior cobertura para a classifica√ß√£o de textos
como n√£o persuasivos. A primeira regra foi baseada em 78 textos n√£o persuasivos,
enquanto a segunda, cobre 70 textos n√£o persuasivos, todos provenientes da base de
treino.

* SE (total de caracteres <= 32,5) e (4,9 < m√©dia de caracteres por palavra <=
5,708) e (vari√¢ncia de caracteres por palavra <= 10,32) e (frequ√™ncia de pontua√ß√£o
<= 4,5) e (1,5 < frequ√™ncia de letras mai√∫sculas <= 8,5) e (frequ√™ncia de
pontua√ß√£o > 0,5) e (vari√¢ncia de caracteres por frase <= 44,5), ENT√ÉO (Texto
= ‚ÄúN√£o persuasivo‚Äù).
* SE (total de caracteres <= 32,5) e (frequ√™ncia de letras mai√∫sculas <= 0,5) e
(frequ√™ncia de pontua√ß√£o <= 4,5) e (vari√¢ncia de caracteres por frase <= 44,5),
ENT√ÉO (Texto = ‚ÄúN√£o persuasivo‚Äù).

Essas regras cobrem um total de 860 textos de memes, o que representa um total de
aproximadamente 7,5% da base de treino balanceada por `oversampling`. Podemos ver pelas
regras a diferen√ßa entre textos persuasivos e n√£o persuasivos, por exemplo, no atributo
‚Äútotal de caracteres‚Äù. As regras exibidas nos mostram que um elevado valor de caracteres
tende a levar o texto a ser persuasivo.

Para uma an√°lise comparativa, as tabelas a seguir apresentam as principais estat√≠sticas
dos atributos para os textos persuasivos e para os textos n√£o
persuasivos, respectivamente.

* Textos persuasivos:
  
![estatisticas_memes_persuasivos](https://github.com/user-attachments/assets/c96405f9-b1cb-4fe3-b2d1-d36feb5145ed)

* Textos n√£o persuasivos:
  
![estatisticas_memes_naopersuasivos](https://github.com/user-attachments/assets/073ecc26-3d07-429a-8898-cd0770451d7e)

Alguns atributos possuem diferen√ßas mais significativas entre os textos persuasivos
e n√£o persuasivos. Conforme as regras apresentadas da `√Årvore de Decis√£o` sugeriram, textos
persuasivos possuem, em m√©dia, 126% mais caracteres do que textos n√£o persuasivos.
Essa diferen√ßa tamb√©m pode ser vista na quantidade m√°xima de caracteres, onde os textos
persuasivos representam um aumento de 195% em rela√ß√£o aos textos n√£o persuasivos. O
desvio padr√£o desse atributo em textos n√£o persuasivos, menor que a metade para textos
persuasivos, indica uma dispers√£o menor dessa vari√°vel nesse contexto, fortalecendo a regra
de que quanto menor for o total de caracteres no texto, mais propenso ele √© a ser n√£o
persuasivo.

O atributo ‚Äúfrequ√™ncia de letras mai√∫sculas‚Äù tamb√©m apresenta diferen√ßas mais
not√°veis entre as duas classifica√ß√µes. Textos persuasivos possuem, em m√©dia, quase o
dobro da quantidade de letras mai√∫sculas de textos n√£o persuasivos. O valor m√°ximo
desse atributo, por exemplo, aumenta em 220% nos textos persuasivos. Essas estat√≠sticas tamb√©m refor√ßam as regras da `√Årvore de Decis√£o`, que indicam que um n√∫mero maior de
letras mai√∫sculas no texto os aproxime da classifica√ß√£o como persuasivo.

### Conclus√£o

Este trabalho abordou a classifica√ß√£o de persuas√£o em textos de memes, utilizando
uma abordagem baseada em engenharia de caracter√≠sticas. Para isso, utilizou-se dos modelos
de `√Årvore de Decis√£o`, `Floresta Aleat√≥ria` e `Regress√£o Log√≠stica`. A explora√ß√£o do
problema de classifica√ß√£o de persuas√£o em textos de memes √© algo novo, levando este
trabalho a realizar este estudo em um contexto mais desafiador do que a classifica√ß√£o de
persuas√£o em outros tipos de texto, como artigos de not√≠cias, por exemplo.

A engenharia de caracter√≠sticas foi empregada para extrair atributos num√©ricos
dos textos presentes nos memes, visando sua aplica√ß√£o em algoritmos de classifica√ß√£o. Os
atributos utilizados foram baseados na metodologia descrita por Cruz, Rocha e Cardoso
(2019), que realizaram a classifica√ß√£o de persuas√£o em textos de artigos. No contexto dos
textos de memes, estamos lidando com conte√∫dos mais curtos e informais.

Os experimentos realizados apontaram que os resultados alcan√ßados pela `√Årvore
de Decis√£o` e `Floresta Aleat√≥ria` foram, em geral, superiores do que a `Regress√£o Log√≠stica`.
A `Regress√£o Log√≠stica` obteve um desempenho melhor apenas na precis√£o, enquanto a
`√Årvore de Decis√£o` e `Floresta Aleat√≥ria` tiveram melhores acur√°cia, recall e F1-Score. A
`√Årvore de Decis√£o` e a `Floresta Aleat√≥ria` tiveram desempenhos aproximados entre si.
Neste caso, a vantagem da `√Årvore de Decis√£o` se d√° pelo fato de se tratar de um modelo
facilmente interpret√°vel, com regras claras para a classifica√ß√£o.

Tr√™s diferentes experimentos foram realizados, com diferentes atributos e balanceamentos.
O `experimento 3`, no cen√°rio com `oversampling`, apresentou tr√™s m√©tricas de
avalia√ß√£o com os maiores valores entre todos os experimentos. Esses resultados foram
alcan√ßados com a `Floresta Aleat√≥ria`, que obteve uma acur√°cia de 0,8130, um recall de
0,8910 e um F1-Score de 0,8894. Contudo, por terem desempenhos pr√≥ximos entre si, o
experimento 1 apresenta destaque em rela√ß√£o aos demais, por sua maior simplicidade e
clareza nos atributos utilizados. Neste caso, utilizaram-se os atributos propostos por Cruz
et al. (2019), mas sem a inclus√£o da medida TF-IDF. Neste experimento, o cen√°rio com
balanceamento por `oversampling` se saiu melhor.

No `experimento 1`, com `oversampling`, a `Floresta Aleat√≥ria` aparece com o melhor
desempenho, alcan√ßando uma acur√°cia de 0,8020 e um F1-Score de 0,8833. A `√Årvore de
Decis√£o` alcan√ßa valores pr√≥ximos, com uma acur√°cia de 0,7730 e um F1-Score de 0,8638.
A `Regress√£o Log√≠stica` se destaca na precis√£o, com um valor de 0,9337. Embora a `Floresta
Aleat√≥ria` tenha um desempenho levemente melhor do que a `√Årvore de Decis√£o`, destaca-se
a vantagem da `√Årvore de Decis√£o` por sua interpretabilidade.

O balanceamento de classes se mostrou uma importante estrat√©gia para gerar um
equil√≠brio nos dados, dividindo a base de treino com 50% de observa√ß√µes como textos
persuasivos e 50% de observa√ß√µes como textos n√£o persuasivos. Isso gerou um maior
equil√≠brio entre falsos positivos e falsos negativos, uma vez que diminuiu a tend√™ncia do
modelo em classificar novas observa√ß√µes como persuasivas. Antes do balanceamento, a
maioria das observa√ß√µes da base de teste era classificada como persuasiva. Como a maior
parte de base de teste √©, de fato, persuasiva, isso gerava um alto valor de falsos positivos,
bem como de verdadeiros positivos.

Por fim, apresenta-se a seguir ideias para trabalhos futuros, tais como:

* Cria√ß√£o de um sistema em duas etapas. A primeira etapa, realizada neste trabalho,
classifica o texto como persuasivo ou n√£o. A segunda etapa, ent√£o, consiste
em classificar qual ou quais t√©cnicas de persuas√£o foram utilizadas nos memes
classificados como persuasivos na primeira etapa.
* Gerar novos atributos preditivos a partir do texto, como por exemplo, elementos
sem√¢nticos. Desta forma, pode-se incluir atributos como total de adjetivos, total
de verbos, entre outros.
* Na gera√ß√£o de novos atributos pode-se, ainda, criar listas com palavras positivas
ou negativas, gerando uma contagem para cada caso e utilizando esses valores
como atributos. Essas listas podem ser criadas a partir de adjetivos ou de palavras
espec√≠ficas que fa√ßam parte do contexto do problema.
* Avalia√ß√£o de embeddings sem√¢nticos como atributos, m√©todo que j√° apresentou
bons resultados em outros trabalhos recentes. Contudo, neste caso, h√° a desvantagem
de n√£o ser um m√©todo interpret√°vel, diferentemente da √Årvore de Decis√£o,
por exemplo.
* Cria√ß√£o de um l√©xico com unigramas e bigramas frequentemente presentes em
textos persuasivos, podendo utilizar a frequ√™ncia absoluta de cada caso como
atributo preditivo.
* Balancear a base de treino com diferentes propor√ß√µes entre as duas classes, al√©m
da divis√£o realizada de 50% para persuas√£o e 50% para n√£o persuas√£o.

